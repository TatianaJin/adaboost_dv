{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaboost_exp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path\n",
    "\n",
    "\"\"\"three datasets: a9a, breast-cancer, gisette\"\"\"\n",
    "\n",
    "data_dir = \"/home/tati/Documents/data/\"\n",
    "\n",
    "a9 = data_dir + \"a9/a9a.txt\"\n",
    "a9_test = data_dir + \"a9/a9a.t\"\n",
    "\n",
    "breast = data_dir + \"breast-cancer/breast-cancer.txt\"\n",
    "\n",
    "gisette = data_dir + \"gisette/gisette_scale\"\n",
    "gisette_test = data_dir + \"gisette/gisette_scale.t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load breast-cancer dataset and split into train/test by 0.8/0.2\n",
    "breast = load_svmlight_file(breast, n_features=10)\n",
    "breast_X, breast_X_test, breast_y, breast_y_test = train_test_split(\n",
    "    breast[0], breast[1], train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 0] error=0.0714285714286\n",
      "[Iter 1] error=0.0714285714286\n",
      "[Iter 2] error=0.0457875457875\n",
      "[Iter 3] error=0.0457875457875\n",
      "[Iter 4] error=0.0384615384615\n",
      "[Iter 5] error=0.032967032967\n",
      "[Iter 6] error=0.0384615384615\n",
      "[Iter 7] error=0.0347985347985\n",
      "[Iter 8] error=0.032967032967\n",
      "[Iter 9] error=0.0311355311355\n",
      "[Iter 10] error=0.0384615384615\n",
      "[Iter 11] error=0.025641025641\n",
      "[Iter 12] error=0.0311355311355\n",
      "[Iter 13] error=0.0311355311355\n",
      "[Iter 14] error=0.0311355311355\n",
      "[Iter 15] error=0.032967032967\n",
      "[Iter 16] error=0.021978021978\n",
      "[Iter 17] error=0.025641025641\n",
      "[Iter 18] error=0.025641025641\n",
      "[Iter 19] error=0.025641025641\n",
      "[Iter 20] error=0.025641025641\n",
      "[Iter 21] error=0.0238095238095\n",
      "[Iter 22] error=0.0238095238095\n",
      "[Iter 23] error=0.0238095238095\n",
      "[Iter 24] error=0.021978021978\n",
      "[Iter 25] error=0.0238095238095\n",
      "[Iter 26] error=0.0238095238095\n",
      "[Iter 27] error=0.021978021978\n",
      "[Iter 28] error=0.021978021978\n",
      "[Iter 29] error=0.021978021978\n",
      "[Iter 30] error=0.0201465201465\n",
      "[Iter 31] error=0.0201465201465\n",
      "[Iter 32] error=0.0201465201465\n",
      "[Iter 33] error=0.021978021978\n",
      "[Iter 34] error=0.0201465201465\n",
      "[Iter 35] error=0.021978021978\n",
      "[Iter 36] error=0.0201465201465\n",
      "[Iter 37] error=0.021978021978\n",
      "[Iter 38] error=0.021978021978\n",
      "[Iter 39] error=0.021978021978\n",
      "[Iter 40] error=0.0201465201465\n",
      "[Iter 41] error=0.021978021978\n",
      "[Iter 42] error=0.0201465201465\n",
      "[Iter 43] error=0.0201465201465\n",
      "[Iter 44] error=0.018315018315\n",
      "[Iter 45] error=0.0201465201465\n",
      "[Iter 46] error=0.018315018315\n",
      "[Iter 47] error=0.0201465201465\n",
      "[Iter 48] error=0.018315018315\n",
      "[Iter 49] error=0.018315018315\n",
      "[Iter 50] error=0.0164835164835\n",
      "[Iter 51] error=0.018315018315\n",
      "[Iter 52] error=0.0164835164835\n",
      "[Iter 53] error=0.018315018315\n",
      "[Iter 54] error=0.014652014652\n",
      "[Iter 55] error=0.014652014652\n",
      "[Iter 56] error=0.0164835164835\n",
      "[Iter 57] error=0.0164835164835\n",
      "[Iter 58] error=0.0164835164835\n",
      "[Iter 59] error=0.0164835164835\n",
      "[Iter 60] error=0.0164835164835\n",
      "[Iter 61] error=0.014652014652\n",
      "[Iter 62] error=0.0164835164835\n",
      "[Iter 63] error=0.014652014652\n",
      "[Iter 64] error=0.0164835164835\n",
      "[Iter 65] error=0.014652014652\n",
      "[Iter 66] error=0.0164835164835\n",
      "[Iter 67] error=0.014652014652\n",
      "[Iter 68] error=0.0164835164835\n",
      "[Iter 69] error=0.014652014652\n",
      "[Iter 70] error=0.0164835164835\n",
      "[Iter 71] error=0.014652014652\n",
      "[Iter 72] error=0.014652014652\n",
      "[Iter 73] error=0.014652014652\n",
      "[Iter 74] error=0.014652014652\n",
      "[Iter 75] error=0.0128205128205\n",
      "[Iter 76] error=0.014652014652\n",
      "[Iter 77] error=0.0128205128205\n",
      "[Iter 78] error=0.010989010989\n",
      "[Iter 79] error=0.0128205128205\n",
      "[Iter 80] error=0.010989010989\n",
      "[Iter 81] error=0.0128205128205\n",
      "[Iter 82] error=0.010989010989\n",
      "[Iter 83] error=0.0128205128205\n",
      "[Iter 84] error=0.010989010989\n",
      "[Iter 85] error=0.010989010989\n",
      "[Iter 86] error=0.0128205128205\n",
      "[Iter 87] error=0.00915750915751\n",
      "[Iter 88] error=0.0128205128205\n",
      "[Iter 89] error=0.010989010989\n",
      "[Iter 90] error=0.0128205128205\n",
      "[Iter 91] error=0.010989010989\n",
      "[Iter 92] error=0.010989010989\n",
      "[Iter 93] error=0.010989010989\n",
      "[Iter 94] error=0.010989010989\n",
      "[Iter 95] error=0.00915750915751\n",
      "[Iter 96] error=0.00915750915751\n",
      "[Iter 97] error=0.00915750915751\n",
      "[Iter 98] error=0.00915750915751\n",
      "[Iter 99] Dynamically adjusting votes\n",
      "[Iter 99] error=0.331501831502\n",
      "fitting time: 0.2942802906036377s\n",
      "DV error=0.36496350365, time=0.8999290466308594\n"
     ]
    }
   ],
   "source": [
    "clf = example_DV(breast_X, breast_y, breast_X_test, breast_y_test,\n",
    "           dv_interval=100,\n",
    "           n_estimators=100,\n",
    "           dv_max_iter=200,\n",
    "           dv_loss=\"log\",\n",
    "           dv_penalty=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78202188,  1.07185103,  1.22613221,  0.65261573,  0.5431024 ,\n",
       "       -0.08829013,  0.34755345,  0.4951297 ,  0.43422192,  0.41010288,\n",
       "       -0.2932333 ,  0.26452941,  0.2319877 ,  0.30456159,  0.32795046,\n",
       "        0.25473877,  0.10983528,  0.42290123, -0.28040484,  0.23271282,\n",
       "       -0.31302855,  0.22217885, -0.33673187,  0.19036251,  0.38897823,\n",
       "        0.4078458 ,  0.2539559 ,  0.31259136, -0.23787338,  0.21277345,\n",
       "       -0.31180781,  0.18642592, -0.35607712,  0.17118241, -0.36009282,\n",
       "        0.12766243, -0.34484649,  0.19244998, -0.36012856,  0.19866847,\n",
       "       -0.35942424,  0.16680567, -0.34614564,  0.16976236, -0.36532619,\n",
       "        0.16068566, -0.36866236,  0.18207395,  0.29116797,  0.14436662,\n",
       "       -0.32508878,  0.17697096, -0.36371818,  0.18704013, -0.02367221,\n",
       "       -0.30298112,  0.17141973, -0.36826682,  0.17690355, -0.37288127,\n",
       "        0.1489259 , -0.37846276,  0.15437204, -0.37809914,  0.17713796,\n",
       "        0.10551228,  0.21891157, -0.39291992,  0.15138653, -0.38507686,\n",
       "        0.12523938,  0.24155392,  0.3030805 ,  0.40628789,  0.332604  ,\n",
       "       -0.39056534,  0.15815693,  0.37017126,  0.335407  ,  0.22503107,\n",
       "       -0.33433129,  0.17163869, -0.35972406,  0.14697475,  0.27375131,\n",
       "       -0.29350497,  0.1588719 , -0.37016002,  0.16095837, -0.37258828,\n",
       "        0.15505654, -0.38195021,  0.14453091, -0.38218086,  0.12945057,\n",
       "        0.05620008,  0.15423835, -0.38115064,  0.17168132, -0.38176003])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.estimator_weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BINARY time=0.09848570823669434\n",
      "\t[Iter 0]: error=0.0714285714286\n",
      "\t[Iter 1]: error=0.0714285714286\n",
      "\t[Iter 2]: error=0.0457875457875\n",
      "\t[Iter 3]: error=0.0457875457875\n",
      "\t[Iter 4]: error=0.0384615384615\n",
      "\t[Iter 5]: error=0.032967032967\n",
      "\t[Iter 6]: error=0.0384615384615\n",
      "\t[Iter 7]: error=0.0347985347985\n",
      "\t[Iter 8]: error=0.032967032967\n",
      "\t[Iter 9]: error=0.0311355311355\n",
      "\t[Iter 10]: error=0.0384615384615\n",
      "\t[Iter 11]: error=0.025641025641\n",
      "\t[Iter 12]: error=0.0311355311355\n",
      "\t[Iter 13]: error=0.0311355311355\n",
      "\t[Iter 14]: error=0.0311355311355\n",
      "\t[Iter 15]: error=0.032967032967\n",
      "\t[Iter 16]: error=0.021978021978\n",
      "\t[Iter 17]: error=0.025641025641\n",
      "\t[Iter 18]: error=0.025641025641\n",
      "\t[Iter 19]: error=0.025641025641\n",
      "\t[Iter 20]: error=0.025641025641\n",
      "\t[Iter 21]: error=0.0238095238095\n",
      "\t[Iter 22]: error=0.0238095238095\n",
      "\t[Iter 23]: error=0.0238095238095\n",
      "\t[Iter 24]: error=0.021978021978\n",
      "\t[Iter 25]: error=0.0238095238095\n",
      "\t[Iter 26]: error=0.0238095238095\n",
      "\t[Iter 27]: error=0.021978021978\n",
      "\t[Iter 28]: error=0.021978021978\n",
      "\t[Iter 29]: error=0.021978021978\n",
      "\t[Iter 30]: error=0.0201465201465\n",
      "\t[Iter 31]: error=0.0201465201465\n",
      "\t[Iter 32]: error=0.0201465201465\n",
      "\t[Iter 33]: error=0.021978021978\n",
      "\t[Iter 34]: error=0.0201465201465\n",
      "\t[Iter 35]: error=0.021978021978\n",
      "\t[Iter 36]: error=0.0201465201465\n",
      "\t[Iter 37]: error=0.021978021978\n",
      "\t[Iter 38]: error=0.021978021978\n",
      "\t[Iter 39]: error=0.021978021978\n",
      "\t[Iter 40]: error=0.0201465201465\n",
      "\t[Iter 41]: error=0.021978021978\n",
      "\t[Iter 42]: error=0.0201465201465\n",
      "\t[Iter 43]: error=0.0201465201465\n",
      "\t[Iter 44]: error=0.018315018315\n",
      "\t[Iter 45]: error=0.0201465201465\n",
      "\t[Iter 46]: error=0.018315018315\n",
      "\t[Iter 47]: error=0.0201465201465\n",
      "\t[Iter 48]: error=0.018315018315\n",
      "\t[Iter 49]: error=0.018315018315\n"
     ]
    }
   ],
   "source": [
    "clf = example_BINARY(breast_X, breast_y, breast_X, breast_y,\n",
    "           n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_init = np.array([clf.estimator_weights_])\n",
    "coef_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=False,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_model = LogisticRegression(fit_intercept=False,\n",
    "                                max_iter=100,\n",
    "                                penalty='l2',\n",
    "                                C=1,\n",
    "                                warm_start=True)\n",
    "X_map = np.array([est.predict(breast_X) for est in clf.estimators_]).T\n",
    "vote_model.coef_ = coef_init\n",
    "vote_model.fit(X_map, breast_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018315018315018316"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf.estimator_weights_ = vote_model.coef_[0]\n",
    "(clf.predict(breast_X) != breast_y).sum() / len(breast_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0054945054945054949"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vote_model.predict(X_map) != breast_y).sum() /  len(breast_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02197802197802198"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression(fit_intercept=True,\n",
    "                                max_iter=20,\n",
    "                                penalty='l1',\n",
    "                                C=10)\n",
    "log_model.fit(breast_X, breast_y)\n",
    "print(log_model.n_iter_)\n",
    "(log_model.predict(breast_X) != breast_y).sum() /  len(breast_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clf.estimators_[0].predict(breast_X)== clf.n_classes_).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = sum((estimator.predict(breast_X) == clf.classes_[:, np.newaxis]).T * w for estimator, w in\n",
    "zip(clf.estimators_, clf.estimator_weights_)) / clf.estimator_weights_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.68984645,  0.31015355],\n",
       "       [-0.71541758,  0.28458242],\n",
       "       [-0.69744925,  0.30255075],\n",
       "       ..., \n",
       "       [-0.71386424,  0.28613576],\n",
       "       [-0.72645614,  0.27354386],\n",
       "       [-0.39158118,  0.60841882]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:,0] *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  2.,  2.,  2.,  2.,  2.,  4.,  2.,  2.,  2.,  2.,  4.,  2.,\n",
       "        2.,  4.,  2.,  2.,  2.,  4.,  2.,  4.,  2.,  2.,  2.,  4.,  2.,\n",
       "        2.,  2.,  2.,  4.,  4.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,\n",
       "        4.,  2.,  2.,  4.,  2.,  4.,  2.,  2.,  2.,  2.,  2.,  4.,  2.,\n",
       "        2.,  2.,  4.,  2.,  2.,  2.,  4.,  4.,  2.,  4.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  4.,  4.,  2.,  2.,  2.,  2.,  4.,  2.,  4.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  4.,  4.,  2.,  2.,  2.,  4.,  2.,\n",
       "        4.,  4.,  2.,  2.,  2.,  4.,  2.,  2.,  2.,  2.,  4.,  2.,  4.,\n",
       "        4.,  2.,  2.,  2.,  4.,  2.,  2.,  2.,  2.,  4.,  2.,  4.,  2.,\n",
       "        2.,  2.,  2.,  4.,  4.,  2.,  4.,  2.,  2.,  2.,  2.,  4.,  4.,\n",
       "        4.,  2.,  2.,  2.,  2.,  4.,  4.,  2.,  4.,  2.,  2.,  2.,  2.,\n",
       "        2.,  4.,  2.,  4.,  2.,  4.,  4.,  4.,  2.,  2.,  2.,  4.,  2.,\n",
       "        2.,  4.,  4.,  2.,  2.,  2.,  2.,  2.,  4.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  4.,  2.,  2.,  4.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,\n",
       "        2.,  2.,  4.,  2.,  4.,  2.,  2.,  4.,  4.,  4.,  2.,  4.,  4.,\n",
       "        4.,  2.,  4.,  2.,  2.,  2.,  2.,  4.,  4.,  2.,  2.,  4.,  2.,\n",
       "        4.,  2.,  2.,  4.,  2.,  2.,  2.,  2.,  4.,  2.,  2.,  4.,  4.,\n",
       "        2.,  4.,  2.,  2.,  2.,  2.,  4.,  4.,  4.,  4.,  4.,  4.,  2.,\n",
       "        2.,  2.,  2.,  4.,  4.,  2.,  2.,  2.,  2.,  2.,  4.,  4.,  2.,\n",
       "        2.,  2.,  4.,  2.,  2.,  2.,  4.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  4.,  4.,  2.,  4.,  2.,  2.,  4.,  4.,\n",
       "        4.,  2.,  2.,  2.,  4.,  2.,  4.,  2.,  2.,  4.,  4.,  2.,  4.,\n",
       "        4.,  2.,  4.,  2.,  4.,  4.,  4.,  4.,  2.,  4.,  2.,  4.,  4.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  4.,  2.,  4.,  2.,  2.,  2.,  4.,\n",
       "        4.,  2.,  2.,  2.,  4.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  4.,  2.,  4.,  2.,  2.,  2.,  4.,  4.,  4.,\n",
       "        4.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,  2.,  2.,  2.,  2.,\n",
       "        2.,  4.,  2.,  2.,  4.,  2.,  4.,  2.,  4.,  4.,  2.,  4.,  2.,\n",
       "        2.,  2.,  4.,  2.,  2.,  2.,  4.,  2.,  4.,  2.,  4.,  4.,  2.,\n",
       "        2.,  2.,  4.,  2.,  2.,  4.,  2.,  2.,  2.,  2.,  4.,  2.,  4.,\n",
       "        2.,  4.,  2.,  2.,  2.,  2.,  2.,  4.,  4.,  4.,  4.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,  2.,  4.,  4.,\n",
       "        2.,  2.,  2.,  2.,  4.,  2.,  4.,  2.,  4.,  4.,  2.,  2.,  2.,\n",
       "        2.,  4.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,  4.,  4.,  4.,  2.,\n",
       "        4.,  2.,  4.,  2.,  2.,  2.,  4.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  4.,  2.,  4.,  4.,  4.,  2.,  4.,  2.,  4.,  4.,  2.,  2.,\n",
       "        2.,  4.,  2.,  4.,  2.,  4.,  2.,  4.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  4.,  4.,  2.,  2.,  4.,  2.,  4.,  4.,  4.,  4.,\n",
       "        2.,  2.,  2.,  4.,  2.,  2.,  4.,  4.,  2.,  2.,  4.,  2.,  4.,\n",
       "        2.,  4.,  2.,  4.,  2.,  4.,  2.,  2.,  2.,  2.,  2.,  4.,  2.,\n",
       "        4.,  2.,  2.,  2.,  2.,  2.,  4.,  4.,  4.,  2.,  2.,  2.,  2.,\n",
       "        4.,  2.,  4.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  4.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_.take(pred>0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
